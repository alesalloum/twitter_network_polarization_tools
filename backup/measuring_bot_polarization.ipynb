{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pickle\n",
    "from random import choices, sample\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First read the bot and banned IDs\n",
    "\n",
    "with open('relevant_bots.p', 'rb') as handle:\n",
    "    bots = pickle.load(handle)\n",
    "\n",
    "with open('relevant_bans.p', 'rb') as handle:\n",
    "    bans = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "botlist = bots | bans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "botlist = set([str(el) for el in botlist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the retweet network and the partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_gml(\"final_test.gml\")\n",
    "print(nx.info(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_partition_users, right_partition_users = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"com1.txt\") as f1:\n",
    "    lines = f1.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    left_partition_users.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"com2.txt\") as f2:\n",
    "    lines = f2.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    right_partition_users.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the edge-betweenness values\n",
    "with open('ebdict.pickle', 'rb') as handle:\n",
    "    dict_edgebetweenness = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BBC_score(graph, dict_edges, partition1, partition2):\n",
    "    \n",
    "    # Graph partition\n",
    "    #c = list(greedy_modularity_communities(graph))\n",
    "    #left_partition_users = list(c[0])\n",
    "    #right_partition_users = list(c[1])\n",
    "    \n",
    "    left_partition_users = partition1\n",
    "    right_partition_users = partition2\n",
    "    \n",
    "    # Getting the edges in the cut\n",
    "    eb_list = []\n",
    "    \n",
    "    for i in range(len(left_partition_users)):\n",
    "        name1 = left_partition_users[i]\n",
    "    \n",
    "        for j in range(len(right_partition_users)):\n",
    "            name2 = right_partition_users[j]\n",
    "        \n",
    "            if (graph.has_edge(name1, name2)):\n",
    "\n",
    "                    if ((name1, name2) in dict_edges):\n",
    "                        edge_betweenness = dict_edges[(name1, name2)]\n",
    "                        eb_list.append(edge_betweenness)\n",
    "\n",
    "                    else:\n",
    "                        edge_betweenness = dict_edges[(name2, name1)]\n",
    "                        eb_list.append(edge_betweenness)\n",
    "                    \n",
    "    \n",
    "    #print(\"Length of cut: \", len(eb_list))\n",
    "    #print(\"Length of cut/num edges\", len(eb_list)*1.0/len(graph.edges))\n",
    "    \n",
    "    # Let us sample from the distributions\n",
    "    #print(eb_list)\n",
    "    cut_dist = choices(eb_list, k=10000)\n",
    "    all_dist = choices(list(dict_edges.values()), k=10000)\n",
    "    \n",
    "    kl_divergence = stats.entropy(all_dist, cut_dist)\n",
    "    \n",
    "    BCC = 1-2.71828**(-kl_divergence)\n",
    "    \n",
    "    return BCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BBC_original_graph = []\n",
    "\n",
    "for _ in range(1000):\n",
    "    \n",
    "    BBC_original_graph.append(BBC_score(G, dict_edgebetweenness, left_partition_users, right_partition_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(BBC_original_graph, label = \"Original network\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Measuring bot-polarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ht = \"ilmastonmuutos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_gml(ht + \"/\" + ht +\"_retweet_network_giant.gml\")\n",
    "print(nx.info(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The number of bots present in our converstation graph: \", len(botlist & set(G.nodes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bots_in_graph = botlist & set(G.nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random node removal vs. removing the bots from the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_rn = G.copy() # graph from which we remove random nodes \n",
    "G_bn = G.copy() # graph from which we remove bot nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "N_sample = 500\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RN, BN = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    \n",
    "    G_rn = G.copy() # graph from which we remove random nodes \n",
    "    G_bn = G.copy() # graph from which we remove bot nodes\n",
    "    \n",
    "    to_be_removed_RN = set(sample(list(G.nodes), N_sample))\n",
    "    to_be_removed_BN = set(sample(list(bots_in_graph), N_sample))\n",
    "    \n",
    "    G_rn.remove_nodes_from(to_be_removed_RN)\n",
    "    G_bn.remove_nodes_from(to_be_removed_BN)\n",
    "    \n",
    "    dict_edgebetweenness_rn = nx.edge_betweenness_centrality(G_rn)\n",
    "    dict_edgebetweenness_bn = nx.edge_betweenness_centrality(G_bn)\n",
    "    \n",
    "    community1_users_rn = [user for user in community1_users if user not in to_be_removed_RN]\n",
    "    community2_users_rn = [user for user in community2_users if user not in to_be_removed_RN]\n",
    "\n",
    "    community1_users_bn = [user for user in community1_users if user not in to_be_removed_BN]\n",
    "    community2_users_bn = [user for user in community2_users if user not in to_be_removed_BN]\n",
    "    \n",
    "    for _ in range(80):\n",
    "        \n",
    "        RN.append(BBC_score(G_rn, dict_edgebetweenness_rn, community1_users_rn, community2_users_rn))\n",
    "        BN.append(BBC_score(G_bn, dict_edgebetweenness_bn, community1_users_bn, community2_users_bn))\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "    print(\"Iteration number: \", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "\n",
    "ax.hist(RN, label = \"RN removed\")\n",
    "ax.hist(BN, label = \"BN removed\", alpha=0.8)\n",
    "ax.legend()\n",
    "\n",
    "fig.savefig(ht+\"_bcc.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean: \", np.mean(RN))\n",
    "print(\"Standard deviation: \", np.std(RN))\n",
    "\n",
    "print(\"Mean: \", np.mean(BN))\n",
    "print(\"Standard deviation: \", np.std(BN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Computing the bot proportions and testing significance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H0: p1 = p2, where p1 is the proportion from the first population, and p2 is the proportion from the second population.\n",
    "\n",
    "Let the significance level be 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_p_value(p_anti, p_pro, n_anti, n_pro, n_total_bots):\n",
    "    p_diff = p_anti-p_pro\n",
    "    p_all = n_total_bots/(n_anti + n_pro)\n",
    "    inner = p_all*(1-p_all)*((1/n_anti) + (1/n_pro))\n",
    "    standard_error = np.sqrt(inner)\n",
    "    t_statistic = p_diff/standard_error\n",
    "    #print(t_statistic)\n",
    "    p_value = stats.norm.sf(abs(t_statistic))\n",
    "    \n",
    "    return p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ht = \"sote\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "community1_users, community2_users = [], []\n",
    "\n",
    "with open(ht + \"/\" + ht + \"_community1.txt\") as f1:\n",
    "    lines = f1.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    community1_users.append(line)\n",
    "    \n",
    "with open(ht + \"/\" + ht + \"_community2.txt\") as f2:\n",
    "    lines = f2.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    community2_users.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anti_one = False  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if anti_one:\n",
    "    anti_bubble_size = len(community1_users)\n",
    "    pro_bubble_size = len(community2_users)\n",
    "    anti_bubble = set(community1_users)\n",
    "    pro_bubble = set(community2_users)\n",
    "else:\n",
    "    anti_bubble_size = len(community2_users)\n",
    "    pro_bubble_size = len(community1_users)\n",
    "    anti_bubble = set(community2_users)\n",
    "    pro_bubble = set(community1_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anti_bot_proportion = (len(anti_bubble & botlist))/(anti_bubble_size)\n",
    "pro_bot_proportion = (len(pro_bubble & botlist))/(pro_bubble_size)\n",
    "n_total_bots = len(pro_bubble & botlist) + len(anti_bubble & botlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"%-ANTIBOT: \", round(anti_bot_proportion, 4)*100)\n",
    "print(\"%-PROBOT: \", round(pro_bot_proportion, 4)*100)\n",
    "\n",
    "print(\"P-arvo: \", compute_p_value(anti_bot_proportion, \n",
    "                pro_bot_proportion,\n",
    "                anti_bubble_size,\n",
    "                pro_bubble_size,\n",
    "                n_total_bots))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
