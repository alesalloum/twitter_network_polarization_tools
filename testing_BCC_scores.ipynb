{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx.algorithms.community.modularity_max import greedy_modularity_communities\n",
    "import matplotlib.pyplot as plt\n",
    "from random import choices, sample\n",
    "from scipy import stats\n",
    "import community, pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let us test the effect of polarized sides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_small_bubbles = nx.connected_caveman_graph(2, 10)\n",
    "G_medium_bubbles = nx.connected_caveman_graph(2, 50)\n",
    "G_large_bubbles = nx.connected_caveman_graph(2, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(G_small_bubbles, node_size = 50, alpha=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(G_medium_bubbles, node_size = 50, alpha=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(G_large_bubbles, node_size = 50, alpha=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_edgebetweenness_small = nx.edge_betweenness_centrality(G_small_bubbles, k=None, normalized=True)\n",
    "dict_edgebetweenness_medium = nx.edge_betweenness_centrality(G_medium_bubbles, k=None, normalized=True)\n",
    "dict_edgebetweenness_large = nx.edge_betweenness_centrality(G_large_bubbles, k=None, normalized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BBC_score(graph, dict_edges):\n",
    "    \n",
    "    # Graph partition\n",
    "    #c = list(greedy_modularity_communities(graph))\n",
    "    #left_partition_users = list(c[0])\n",
    "    #right_partition_users = list(c[1])\n",
    "    \n",
    "    #partition = community.best_partition(graph)\n",
    "    #print(partition)\n",
    "    #pos = nx.spring_layout(graph)\n",
    "    #plt.figure(figsize=(8, 8))\n",
    "    #plt.axis('off')\n",
    "    #nx.draw_networkx_nodes(graph, pos, node_size=100, cmap=plt.cm.RdYlBu, node_color=list(partition.values()))\n",
    "    #nx.draw_networkx_edges(graph, pos, alpha=0.3)\n",
    "    #plt.show(graph)\n",
    "    \n",
    "    # Getting the edges in the cut\n",
    "    eb_list = []\n",
    "    \n",
    "    for i in range(len(left_partition_users)):\n",
    "        name1 = left_partition_users[i]\n",
    "    \n",
    "        for j in range(len(right_partition_users)):\n",
    "            name2 = right_partition_users[j]\n",
    "        \n",
    "            if (graph.has_edge(name1, name2)):\n",
    "\n",
    "                    if ((name1, name2) in dict_edges):\n",
    "                        edge_betweenness = dict_edges[(name1, name2)]\n",
    "                        eb_list.append(edge_betweenness)\n",
    "\n",
    "                    else:\n",
    "                        edge_betweenness = dict_edges[(name2, name1)]\n",
    "                        eb_list.append(edge_betweenness)\n",
    "                    \n",
    "    \n",
    "    #print(\"Length of cut: \", len(eb_list))\n",
    "    #print(\"Length of cut/num edges\", len(eb_list)*1.0/len(graph.edges))\n",
    "    \n",
    "    # Let us sample from the distributions\n",
    "    \n",
    "    cut_dist = choices(eb_list, k=10000)\n",
    "    all_dist = choices(list(dict_edges.values()), k=10000)\n",
    "    \n",
    "    kl_divergence = stats.entropy(all_dist, cut_dist)\n",
    "    \n",
    "    BCC = 1-2.71828**(-kl_divergence)\n",
    "    \n",
    "    return BCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"BBC for a graph with small bubbles: \", BBC_score(G_small_bubbles, dict_edgebetweenness_small))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"BBC for a graph with medium bubbles: \", BBC_score(G_medium_bubbles, dict_edgebetweenness_medium))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"BBC for a graph with large bubbles: \", BBC_score(G_large_bubbles, dict_edgebetweenness_large))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SB, MB, LB = [], [], []\n",
    "\n",
    "for _ in range(1000):\n",
    "    \n",
    "    SB.append(BBC_score(G_small_bubbles, dict_edgebetweenness_small))\n",
    "    MB.append(BBC_score(G_medium_bubbles, dict_edgebetweenness_medium))\n",
    "    LB.append(BBC_score(G_large_bubbles, dict_edgebetweenness_large))\n",
    "    \n",
    "plt.hist(SB)\n",
    "plt.hist(MB)\n",
    "plt.hist(LB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(SB, label=\"Small bubbles\")\n",
    "plt.hist(MB, label=\"Medium bubbles\")\n",
    "plt.hist(LB, label=\"Large bubbles\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The size of the polarized bubble affects the BBC score\n",
    "# Let us next analyze the effect of cut size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_small_cut = nx.relaxed_caveman_graph(2, 50, 0.1)\n",
    "G_medium_cut = nx.relaxed_caveman_graph(2, 50, 0.3)\n",
    "G_large_cut = nx.relaxed_caveman_graph(2, 50, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(G_small_cut, node_size = 50, alpha=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(G_medium_cut, node_size = 50, alpha=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(G_large_cut, node_size = 50, alpha=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_edgebetweenness_small = nx.edge_betweenness_centrality(G_small_cut, k=None, normalized=True)\n",
    "dict_edgebetweenness_medium = nx.edge_betweenness_centrality(G_medium_cut, k=None, normalized=True)\n",
    "dict_edgebetweenness_large = nx.edge_betweenness_centrality(G_large_cut, k=None, normalized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"BBC for a graph with small cut: \", BBC_score(G_small_cut, dict_edgebetweenness_small))\n",
    "print(\"BBC for a graph with medium cut: \", BBC_score(G_medium_cut, dict_edgebetweenness_medium))\n",
    "print(\"BBC for a graph with large cut: \", BBC_score(G_large_cut, dict_edgebetweenness_large))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SC, MC, LC = [], [], []\n",
    "\n",
    "for _ in range(1000):\n",
    "    \n",
    "    SC.append(BBC_score(G_small_cut, dict_edgebetweenness_small))\n",
    "    MC.append(BBC_score(G_medium_cut, dict_edgebetweenness_medium))\n",
    "    LC.append(BBC_score(G_large_cut, dict_edgebetweenness_large))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(SC, label = \"Small cut\")\n",
    "plt.hist(MC, label = \"Medium cut\")\n",
    "plt.hist(LC, label = \"Large cut\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The cut size definitely affects the score\n",
    "# Lastly, what about the unequal sized bubbles, let us check!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_balanced = nx.relaxed_caveman_graph(2, 1000, 0.1)\n",
    "#nx.draw(G_balanced, node_size = 50, alpha=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_edgebetweenness_balanced = nx.edge_betweenness_centrality(G_balanced, k=None, normalized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BBC_score(G_balanced, dict_edgebetweenness_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove_10 = sample(range(1000, 2001), int(0.1*len(G_balanced.nodes)*0.5))\n",
    "to_remove_25 = sample(range(1000, 2001), int(0.25*len(G_balanced.nodes)*0.5))\n",
    "to_remove_50 = sample(range(1000, 2001), int(0.5*len(G_balanced.nodes)*0.5))\n",
    "to_remove_75 = sample(range(1000, 2001), int(0.75*len(G_balanced.nodes)*0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_little_unbalanced = G_balanced.copy()\n",
    "G_moderately_unbalanced = G_balanced.copy()\n",
    "G_very_unbalanced = G_balanced.copy()\n",
    "G_super_unbalanced = G_balanced.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_little_unbalanced.remove_nodes_from(to_remove_10)\n",
    "G_moderately_unbalanced.remove_nodes_from(to_remove_25)\n",
    "G_very_unbalanced.remove_nodes_from(to_remove_50)\n",
    "G_super_unbalanced.remove_nodes_from(to_remove_75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_edgebetweenness_little_unbalanced = nx.edge_betweenness_centrality(G_little_unbalanced, k=None, normalized=True)\n",
    "dict_edgebetweenness_moderately_unbalanced = nx.edge_betweenness_centrality(G_moderately_unbalanced, k=None, normalized=True)\n",
    "dict_edgebetweenness_very_unbalanced = nx.edge_betweenness_centrality(G_very_unbalanced, k=None, normalized=True)\n",
    "dict_edgebetweenness_super_unbalanced = nx.edge_betweenness_centrality(G_super_unbalanced, k=None, normalized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"BBC for a graph with small dif: \", BBC_score(G_little_unbalanced, dict_edgebetweenness_little_unbalanced))\n",
    "print(\"BBC for a graph with medium dif: \", BBC_score(G_moderately_unbalanced, dict_edgebetweenness_moderately_unbalanced))\n",
    "print(\"BBC for a graph with large dif: \", BBC_score(G_very_unbalanced, dict_edgebetweenness_very_unbalanced))\n",
    "print(\"BBC for a graph with super dif: \", BBC_score(G_super_unbalanced, dict_edgebetweenness_super_unbalanced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SD, MD, LD, SSD = [], [], [], []\n",
    "\n",
    "for _ in range(200):\n",
    "    \n",
    "    SD.append(BBC_score(G_little_unbalanced, dict_edgebetweenness_little_unbalanced))\n",
    "    MD.append(BBC_score(G_moderately_unbalanced, dict_edgebetweenness_moderately_unbalanced))\n",
    "    LD.append(BBC_score(G_very_unbalanced, dict_edgebetweenness_very_unbalanced))\n",
    "    SSD.append(BBC_score(G_super_unbalanced, dict_edgebetweenness_super_unbalanced))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(SD, label = \"Little unbalanced\")\n",
    "plt.hist(MD, label = \"Moderately unbalanced\")\n",
    "plt.hist(LD, label = \"Very unbalanced\")\n",
    "plt.hist(SSD, label = \"Super unbalanced\", alpha=0.8)\n",
    "plt.legend(loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANALYSIS OF OUR DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ht = \"ilmastonmuutos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: Graph\n",
      "Number of nodes: 15699\n",
      "Number of edges: 51558\n",
      "Average degree:   6.5683\n"
     ]
    }
   ],
   "source": [
    "#Load the network an communities\n",
    "\n",
    "G = nx.read_gml(ht + \"/\" + ht +\"_retweet_network_giant.gml\")\n",
    "print(nx.info(G))\n",
    "\n",
    "#with open('ebdict.pickle', 'rb') as handle:\n",
    "    #dict_edgebetweenness = pickle.load(handle)\n",
    "    \n",
    "dict_edgebetweenness = nx.edge_betweenness_centrality(G, k=None, normalized=True)\n",
    "    \n",
    "left_partition_users, right_partition_users = [], []\n",
    "\n",
    "with open(ht + \"/\" + ht + \"_community1.txt\") as f1:\n",
    "    lines = f1.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    left_partition_users.append(line)\n",
    "    \n",
    "with open(ht + \"/\" + ht + \"_community2.txt\") as f2:\n",
    "    lines = f2.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    right_partition_users.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "OG_NET = []\n",
    "\n",
    "for _ in range(1000):\n",
    "    \n",
    "    OG_NET.append(BBC_score(G, dict_edgebetweenness))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  0.7064279253909453\n",
      "Standard deviation:  0.01585436565650774\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean: \", np.mean(OG_NET))\n",
    "print(\"Standard deviation: \", np.std(OG_NET))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.ones_like(OG_NET)/float(len(OG_NET))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "\n",
    "ax.hist(OG_NET, weights=weights, color=\"coral\", bins=15, label = ht)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(ht+\"_bcc.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 5\n",
    "fig_size[1] = 3\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
